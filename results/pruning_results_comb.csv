Modification,Perplexity_mean,Time_mean
"{'run_mode': 'prune', 'config': 'config.json', 'base_model': 'vinai/PhoGPT-4B-Chat', 'output': 'results/pruning_results_comb.csv', 'instructive_prompt': False, 'measure_time': True, 'output_console': True, 'bnb': 'none', 'load_peft_path': None, 'model_path': '', 'dataset_path': '', 'block_size': 1024, 'precision': 'fp16', 'eval_after_train': None, 'save_full_model': None, 'save_path': './trained_model', 'benchmark': 'perplexity-essay-vn', 'eval_repeat': 5, 'eval_base': True, 'pruning_method': 'combine', 'pruning_rate': [], 'pruning_layer_num': [1, 2, 3, 4, 6], 'pruning_target': '', 'pruning_data': 'c4', 'pruning_n_samples': 128, 'pruning_rand_data': True, 'pruning_batch_size': 32, 'pruning_avg': None, 'pruning_mag_norm': 'l1', 'pruning_grad_T_order': 1}",,
Base model,12.6773828125,0.18850083351135255
Layers [12] pruned by combine method,12.7364453125,0.19005675315856935
"Layers [12, 28] pruned by combine method",13.2084765625,0.18544931411743165
"Layers [12, 28, 14] pruned by combine method",13.619375,0.17743730545043945
"Layers [12, 28, 14, 29] pruned by combine method",14.682187500000001,0.1735471725463867
"Layers [12, 28, 14, 29, 27, 26] pruned by combine method",18.37296875,0.16163234710693358
Modification,Perplexity_mean,Time_mean
"{'run_mode': 'prune', 'config': 'config.json', 'base_model': 'vinai/PhoGPT-4B-Chat', 'output': 'results/pruning_results_comb.csv', 'instructive_prompt': False, 'measure_time': True, 'output_console': True, 'bnb': 'none', 'load_peft_path': None, 'model_path': '', 'dataset_path': '', 'block_size': 1024, 'precision': 'fp16', 'eval_after_train': None, 'save_full_model': None, 'save_path': './trained_model', 'benchmark': 'perplexity-dataset-vnnews', 'eval_repeat': 5, 'eval_base': True, 'pruning_method': 'combine', 'pruning_rate': [], 'pruning_layer_num': [1, 2, 3, 4, 6], 'pruning_target': '', 'pruning_data': 'c4', 'pruning_n_samples': 128, 'pruning_rand_data': True, 'pruning_batch_size': 32, 'pruning_avg': None, 'pruning_mag_norm': 'l1', 'pruning_grad_T_order': 1}",,
Base model,22.085784912109375,0.11473979949951171
Layers [12] pruned by combine method,22.623992919921875,0.11789479255676269
"Layers [12, 28] pruned by combine method",23.75787353515625,0.11373782157897949
"Layers [12, 28, 14] pruned by combine method",25.264434814453125,0.11360607147216797
"Layers [12, 28, 14, 29] pruned by combine method",28.62677001953125,0.10689697265625
"Layers [12, 28, 14, 29, 27, 26] pruned by combine method",40.623291015625,0.11005792617797852
Modification,Perplexity_mean,Time_mean
"{'run_mode': 'prune', 'config': 'config.json', 'base_model': 'vinai/PhoGPT-4B-Chat', 'output': 'results/pruning_results_comb.csv', 'instructive_prompt': False, 'measure_time': True, 'output_console': True, 'bnb': 'none', 'load_peft_path': None, 'model_path': '', 'dataset_path': '', 'block_size': 1024, 'precision': 'fp16', 'eval_after_train': None, 'save_full_model': None, 'save_path': './trained_model', 'benchmark': 'perplexity-essay-vn', 'eval_repeat': 5, 'eval_base': True, 'pruning_method': 'combine', 'pruning_rate': [], 'pruning_layer_num': [1, 2, 3, 4, 6], 'pruning_target': '', 'pruning_data': 'oscarvi', 'pruning_n_samples': 128, 'pruning_rand_data': True, 'pruning_batch_size': 32, 'pruning_avg': None, 'pruning_mag_norm': 'l1', 'pruning_grad_T_order': 1}",,
Base model,12.6773828125,0.1912825584411621
Layers [12] pruned by combine method,12.7364453125,0.19031739234924316
"Layers [12, 28] pruned by combine method",13.2084765625,0.18366804122924804
"Layers [12, 28, 14] pruned by combine method",13.619375,0.1776881694793701
"Layers [12, 28, 14, 29] pruned by combine method",14.682187500000001,0.17258267402648925
"Layers [12, 28, 14, 29, 27, 26] pruned by combine method",18.37296875,0.1615595817565918
Modification,Perplexity_mean,Time_mean
"{'run_mode': 'prune', 'config': 'config.json', 'base_model': 'vinai/PhoGPT-4B-Chat', 'output': 'results/pruning_results_comb.csv', 'instructive_prompt': False, 'measure_time': True, 'output_console': True, 'bnb': 'none', 'load_peft_path': None, 'model_path': '', 'dataset_path': '', 'block_size': 1024, 'precision': 'fp16', 'eval_after_train': None, 'save_full_model': None, 'save_path': './trained_model', 'benchmark': 'perplexity-dataset-vnnews', 'eval_repeat': 5, 'eval_base': True, 'pruning_method': 'combine', 'pruning_rate': [], 'pruning_layer_num': [1, 2, 3, 4, 6], 'pruning_target': '', 'pruning_data': 'oscarvi', 'pruning_n_samples': 128, 'pruning_rand_data': True, 'pruning_batch_size': 32, 'pruning_avg': None, 'pruning_mag_norm': 'l1', 'pruning_grad_T_order': 1}",,
Base model,22.085784912109375,0.10929322242736816
Layers [12] pruned by combine method,22.623992919921875,0.11761436462402344
"Layers [12, 28] pruned by combine method",23.75787353515625,0.11437482833862304
"Layers [12, 28, 14] pruned by combine method",25.264434814453125,0.10978713035583496
"Layers [12, 28, 14, 29] pruned by combine method",28.62677001953125,0.10725336074829102
"Layers [12, 28, 14, 29, 27, 26] pruned by combine method",40.623291015625,0.11691517829895019
