Modification,Perplexity_mean,Time_mean
"{'run_mode': 'prune', 'config': 'config.json', 'base_model': 'vinai/PhoGPT-4B-Chat', 'output': 'results/pruning_results_mag.csv', 'instructive_prompt': False, 'measure_time': True, 'output_console': True, 'bnb': 'none', 'load_peft_path': None, 'model_path': '', 'dataset_path': '', 'block_size': 1024, 'precision': 'fp16', 'eval_after_train': None, 'save_full_model': None, 'save_path': './trained_model', 'benchmark': 'perplexity-essay-vn', 'eval_repeat': 5, 'eval_base': True, 'pruning_method': 'magnitude', 'pruning_rate': [], 'pruning_layer_num': [1, 2, 3, 4, 6], 'pruning_target': '', 'pruning_data': 'c4', 'pruning_n_samples': 1000, 'pruning_rand_data': None, 'pruning_batch_size': 32, 'pruning_avg': None, 'pruning_mag_norm': 'l1', 'pruning_grad_T_order': 1}",,
Base model,12.6773828125,0.19149441719055177
Layers [12] pruned by magnitude method,12.7364453125,0.18585195541381835
"Layers [12, 28] pruned by magnitude method",13.2084765625,0.1800905704498291
"Layers [12, 28, 14] pruned by magnitude method",13.619375,0.17380781173706056
"Layers [12, 28, 14, 29] pruned by magnitude method",14.682187500000001,0.1692042350769043
"Layers [12, 28, 14, 29, 27, 26] pruned by magnitude method",18.37296875,0.1579028606414795
Modification,Perplexity_mean,Time_mean
"{'run_mode': 'prune', 'config': 'config.json', 'base_model': 'vinai/PhoGPT-4B-Chat', 'output': 'results/pruning_results_mag.csv', 'instructive_prompt': False, 'measure_time': True, 'output_console': True, 'bnb': 'none', 'load_peft_path': None, 'model_path': '', 'dataset_path': '', 'block_size': 1024, 'precision': 'fp16', 'eval_after_train': None, 'save_full_model': None, 'save_path': './trained_model', 'benchmark': 'perplexity-dataset-vnnews', 'eval_repeat': 5, 'eval_base': True, 'pruning_method': 'magnitude', 'pruning_rate': [], 'pruning_layer_num': [1, 2, 3, 4, 6], 'pruning_target': '', 'pruning_data': 'c4', 'pruning_n_samples': 1000, 'pruning_rand_data': None, 'pruning_batch_size': 32, 'pruning_avg': None, 'pruning_mag_norm': 'l1', 'pruning_grad_T_order': 1}",,
Base model,22.085784912109375,0.11370558738708496
Layers [12] pruned by magnitude method,22.623992919921875,0.11904335021972656
"Layers [12, 28] pruned by magnitude method",23.75787353515625,0.11448554992675782
"Layers [12, 28, 14] pruned by magnitude method",25.264434814453125,0.10879063606262207
"Layers [12, 28, 14, 29] pruned by magnitude method",28.62677001953125,0.10653524398803711
"Layers [12, 28, 14, 29, 27, 26] pruned by magnitude method",40.623291015625,0.11644296646118164
